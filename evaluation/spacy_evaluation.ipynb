{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29606803",
   "metadata": {},
   "source": [
    "#### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19b9179",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import spacy\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "# --- Loading spaCy model for aspect extraction ---\n",
    "SPACY_MODEL_PATH = '/teamspace/studios/this_studio/Model/spacy/spacy_iteration_004'\n",
    "spacy_nlp = spacy.load(SPACY_MODEL_PATH)\n",
    "#------------------------------------------------\n",
    "TEST_FILE = '/teamspace/studios/this_studio/test2.jsonl'\n",
    "extracted_aspects_all = []\n",
    "ground_truth_aspects_all = []\n",
    "\n",
    "def calculate_iou(true_span, predicted_span):\n",
    "    try:\n",
    "        true_start, true_end = int(true_span[0]), int(true_span[1])\n",
    "        pred_start, pred_end = int(predicted_span[0]), int(predicted_span[1])\n",
    "    except ValueError:\n",
    "        return 0.0  \n",
    "\n",
    "    intersection_start = max(true_start, pred_start)\n",
    "    intersection_end = min(true_end, pred_end)\n",
    "\n",
    "    if intersection_start < intersection_end:\n",
    "        intersection = intersection_end - intersection_start\n",
    "    else:\n",
    "        return 0.0\n",
    "    \n",
    "    union_start = min(true_start, pred_start)\n",
    "    union_end = max(true_end, pred_end)\n",
    "    union = union_end - union_start\n",
    "    return intersection / union  \n",
    "\n",
    "def evaluate_aspect_extraction(pred_aspects_all, gt_aspects_all):\n",
    "    y_true_set = set()\n",
    "    y_pred_set = set()\n",
    "    iou_scores = []\n",
    "    for idx, (preds, gts) in enumerate(zip(pred_aspects_all, gt_aspects_all)):\n",
    "        for gt in gts:\n",
    "            aspect, start, end = gt\n",
    "            if start is not None and end is not None:\n",
    "                y_true_set.add((idx, aspect, int(start), int(end)))\n",
    "        for pred in preds:\n",
    "            aspect, start, end = pred\n",
    "            if start is not None and end is not None:\n",
    "                y_pred_set.add((idx, aspect, int(start), int(end)))\n",
    "\n",
    "    tp = len(y_true_set & y_pred_set)\n",
    "    fp = len(y_pred_set - y_true_set)\n",
    "    fn = len(y_true_set - y_pred_set)\n",
    "\n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0.0\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n",
    "    f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0.0\n",
    "\n",
    "    for true_entity in y_true_set:\n",
    "        for pred_entity in y_pred_set:\n",
    "            if true_entity[1] == pred_entity[1]:  \n",
    "                iou = calculate_iou(true_entity[2:], pred_entity[2:])\n",
    "                iou_scores.append(iou)\n",
    "\n",
    "    average_iou = sum(iou_scores) / len(iou_scores) if iou_scores else 0.0\n",
    "    return precision, recall, f1, average_iou\n",
    "\n",
    "with open(TEST_FILE, 'r') as f:\n",
    "    for line in f:\n",
    "        item = json.loads(line.strip())\n",
    "        sentence = item['sentence']\n",
    "        gt_entity = item['entities']\n",
    "        gt_aspect = (gt_entity['aspect'], gt_entity['start_offset'], gt_entity['end_offset'])\n",
    "        ground_truth_aspects_all.append([gt_aspect])\n",
    "        doc = spacy_nlp(sentence)\n",
    "        pred_aspects = []\n",
    "        for ent in doc.ents:\n",
    "            start = ent.start_char\n",
    "            end = ent.end_char\n",
    "            pred_aspects.append((ent.text, start, end))\n",
    "        extracted_aspects_all.append(pred_aspects)\n",
    "\n",
    "\n",
    "print(\"\\n--- Aspect Extraction Evaluation ---\\n\")\n",
    "precision, recall, f1, average_iou = evaluate_aspect_extraction(extracted_aspects_all, ground_truth_aspects_all)\n",
    "print(f\"Aspect Extraction Precision: {precision:.4f}\")\n",
    "print(f\"Aspect Extraction Recall: {recall:.4f}\")\n",
    "print(f\"Aspect Extraction F1: {f1:.4f}\")\n",
    "print(f\"Average IoU: {average_iou:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea4c5512",
   "metadata": {},
   "source": [
    "#### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba815370",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "iterations = ['1', '2', '3', '4']\n",
    "precision_values = [0.1667, 0.4012, 0.4407, 0.5474]\n",
    "recall_values = [0.0075, 0.5149, 0.5821, 0.5597]\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(iterations, precision_values, marker='o', linestyle='-', color='red', linewidth=2, label='Precision')\n",
    "plt.plot(iterations, recall_values, marker='o', linestyle='-', color='blue', linewidth=2, label='Recall')\n",
    "\n",
    "for i, (p, r) in enumerate(zip(precision_values, recall_values)):\n",
    "    plt.text(i, p + 0.02, f\"{p:.4f}\", ha='center', color='red')\n",
    "    plt.text(i, r + 0.02, f\"{r:.4f}\", ha='center', color='blue')\n",
    "    \n",
    "plt.ylim(0, 1.1)\n",
    "plt.xlabel(\"Iterations\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.title(\"Precision and Recall across iterations\")\n",
    "plt.grid(True, linestyle='--', alpha=0.6)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6950f267",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "iterations = ['1', '2', '3', '4']\n",
    "f1_values = [0.0143, 0.4510, 0.5016, 0.5535]\n",
    "iou_values = [0.2500, 0.0618, 0.0630, 0.0730]\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(iterations, f1_values, marker='o', linestyle='-', color='orange', linewidth=2, label='F1 Score')\n",
    "plt.plot(iterations, iou_values, marker='o', linestyle='--', color='green', linewidth=2, label='IoU')\n",
    "for i, (p, r) in enumerate(zip(f1_values, iou_values)):\n",
    "    plt.text(i, p + 0.02, f\"{p:.4f}\", ha='center', color='orange')\n",
    "    plt.text(i, r + 0.02, f\"{r:.4f}\", ha='center', color='green')\n",
    "\n",
    "plt.ylim(0, 1.1)\n",
    "plt.xlabel(\"Iterations\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.title(\"F1 score and IoU across Iterations\")\n",
    "plt.grid(True, linestyle='--', alpha=0.6)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
